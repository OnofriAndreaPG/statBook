{
    "collab_server" : "",
    "contents" : "\n#Introduzione\n\nI fenomeni biologici, come ad esempio la crescita di una coltura, la cinetica degradativa degli erbicidi nel terreno, la risposta produttiva delle colture a densità crescenti di malerbe o a dosi crescenti di concime, la risposta fitotossica di una specie infestante alla dose di un erbicida, hanno in genere andamenti curvilinei, posseggono punti di massimo o minimo, flessi e, soprattutto, hanno frequentemente asintoti. Pertanto, difficilmente possono essere descritti con funzioni lineari, a meno che non ci accontentiamo di approssimare localmente l'andamento dei dati, in un intervallo ristretto della variabile indipendente.\n\nDa un punto di vista pratico è quindi fondamentale sapere adattare ai dati funzioni curvilinee di ogni tipo. Introduciamo il problema con un esempio.\n\n##Esempio 1\n\nUn suolo è stato trattato con metamitron (un erbicida) alla concentrazione di 100 $ng g^1$. Dopo essere stato opportunamente mescolato, è stato posto in cella climatica alla temperatura di 20 \\textdegree C, distribuito in 24 contenitori di alluminio. In 8 tempi diversi dopo l'inizio del saggio, sono stati prelevati 3 contenitori e sottoposti ad analisi chimica per la determinazione della concentrazione residua dell'erbicida. I dati osservati sono riporati di seguito\n\n```{r}\ndata(degradation)\nhead(degradation, 10)\nplot(Conc ~ Time, data=degradation)\n```\n\nIl grafico suggerisce che la risposta della concentrazione nel tempo è curvilinea, secondo la seguente equazione generale:\n\n$$ Y = f(X, \\theta) + \\epsilon$$\n\ndove $X$ è il tempo, $Y$ la concentrazione, $\\theta$ sono i parametri del modello ed $\\epsilon$ sono i residui, che misurano lo scostamento dei dati osservati dalla risposta attesa, secondo l'equazione prescelta per $f$. E' evidente che $X$ ed $Y$ sono noti, ma resta da scegliere $f$ e da stimare $\\theta$.\n\n#Scelta della funzione\n\nUno dei criteri fondamentali, ancorché empirico, per la selezione di una\ncurva è quello di considerarne la forma, in relazione al fenomeno\nbiologico in studio. In questo senso, possiamo classificare le funzioni in:\n\n-   Curve Lineari\n    1. Retta\n    2. Parabola\n-   Curve convesse/concave\n    1. Funzione esponenziale\n    2. Funzione di potenza\n    3. Funzione logaritmica\n    4. Iperbole rettangolare\n    5. Funzione monomolecolare\n    6. Funzione di Michaelis-Menten\n-   Curve sigmoidali\n    1.  Funzione logistica\n    2.  Funzione di Gompertz\n    3.  Funzione ’valori estremi’\n    4.  Funzione Log-logistica (Equazione di Hill)\n    5.  Weibull-1 (log-Gompertz)\n    6.  Weibull-2 (log-Extreme)\n-   Curve con massimi/minimi\n    1.  Equazione di Brain-Cousens\n    2.  Equazione di Braggs\n\nLa descrizione di queste curve verrà fatta in appendice. In questo caso specifico abbiamo bisogno di una funzione concava verso l'alto e con un asintoto orizzontale coincidente con l'asse delle X. Le conoscenze in relazione alla cinetica di degradazione dei composti chimici ci suggerisce una relazione esponenziale (cinetica del primo ordine), così definita:\n\n$$ Y = A e^{-k \\,X} $$ \n\ndove A è la concentrazione iniziale e $k$ e il tasso di degradazione (costante nel tempo).\n\n#Stima dei parametri\n\nDopo aver definito $f$, dobbiamo stimare i parametri $A$ e $k$. In generale esistono tre tecniche fondamentali:\n\n1. linearizzazione della funzione tramite trasformazione delle variabili;\n2. approssimazione della vera funzione curvilinea con una polinomiale in X;\n3. adattamento ai dati sperimentali di funzioni curvilinee, tramite metodiche di regressione non-lineare.\n\n## Linearizzazione della funzione\n\nNel caso specifico, prendendo il logaritmo di entrambe le parti dell'equazione, otteniamo la seguente trasformazione:\n\n$$ log(Y) = log(A) + X $$\n\nPossiamo quindi trasformare la Y nel suo logaritmo ed utilizzare un modello lineare per la stima dei parametri.\n\n```{r}\nmod <- lm(log(Conc) ~ Time, data=degradation)\nsummary(mod)\n```\n\nLe funzioni linearizzabili per semplice trasformazione delle\nvariabili sono dette *linearizzabili* e presentano il vantaggio di semplificare molto i calcoli richiesti per la stima dei parametri. Un grave svantaggio è dato dal fatto che trasformando la Y si trasforma anche la distribuzione degli errori e quindi bisogna verificare che le assunzioni di base dei modelli lineari (omogeneità delle varianze e normalità dei residui) siano valide nella scala trasformata\n\n```{r}\nplot(residuals(mod) ~ fitted(mod), xlab=\"Fitted data\", ylab=\"Residuals\")\nabline(h=0, lty=2)\n```\n\nIn questo caso specifico, il grafico dei residui suggerisci deviazioni consistenti rispetto alla omogeneità delle varianze, che risultano inversamente proporzionali ai valori attesi (più alto il logaritmo della concentrazione più bassi i residui). Questo fa sospettare che le varianze potrebbero essere omogenee sulla scala originale, impedendoci quindi di analizzare i dati nella scala trasformata.\n\n##Approssimazione della vera funzione tramite una polinomiale in X\n\nIn generale, relazioni matematiche curvilinee possono essere approssimate tramite funzioni polinomiali di ordine \\textit{n}. Le funzioni polinomiali sono molto flessibili; contengono la funzione lineare come caso particolare (n=1) e permette di descrivere curvature anche molto complesse semplicemente aumentando l' ordine della funzione. In questo modo è possibile ottenere un adattamento ai dati sperimentali teoricamente anche perfetto.\n\nLe funzioni polinomiali sono un tipico esempio di funzioni non-lineari nelle variabili, ma lineari nei parametri; esse possono essere trattate ricorrendo alle metodiche di calcolo normalmente utilizzate per la regressione lineare.\n\nGli svantaggi delle funzioni polinomiali sono relativi al fatto che queste presentano raramente giustificazione biologica. Per esempio, con le funzioni polinomiali non è possibile descrivere relazioni asintotiche,\nche sono invece molto comuni in biologia. Nel nostro esempio si potrebbe utilizzare una funzione polinomiale di II grado.\n\n```{r}\nmod2 <- lm(Conc ~ Time + I(Time^2), data=degradation)\nplot(Conc ~ Time, data=degradation)\ncoefs <- coef(mod2)\ncurve(coefs[1] + coefs[2]*x + coefs[3]*x^2, add=T, col=\"red\")\n```\n\nVediamo come la funzione inserita, mentre approssima bene i dati nell'intervallo da 0 a 40 giorni, successivamente mostra una ricrescita, che non ha alcun senso biologico.\n\nIn generale, le polinomiali sono utilizzate quando sia necessario approssimare una funzione curvilinea in un intervallo della X molto ristretto e non consentono nessuna estrapolazione al di fuori di questo intervallo, dato che possono portare a stime della risposta completamente insensate biologicamente.\n\nPer questi motivi l' uso delle funzioni polinomiali dovrebbe\nessere limitato ai casi in cui non si abbia nessuna conoscenza *a priori* dell' andamento del fenomeno. Tra l' altro i moderni supporti informatici consentono di risolvere il problema dell' adattamento diretto di funzioni curvilinee qualunque senza i lunghi calcoli manuali che venivano richiesti fino ad alcuni anni fa.\n\n##Adattamento di funzioni curvilinee qualunque: regressione non-lineare\n\nPer quanto sopra accennato, ogniqualvolta possibile, si preferisce utilizzare metodologie di regressione non-lineare, che permettono di adattare direttamente funzioni curvilinee di qualunque tipo ai dati sperimentali. La stima dei parametri, tuttavia, non è immediata e richiede l'impiego di metodi iterativi  (Gauss-Newton, Steepest Descent, Marquardt, Simplex; alcune informazioni sono riportate in appendice). In questo caso, è necessario fissare delle stime iniziali dei parametri, che vengono corrette in ogni iterazione successiva fino ad ottenere la convergenza sui valori che minimizzano lo scostamento tra i dati osservati e la funzione non-lineare (metodo dei minimi quadrati non-lineari). Ovviamente, trattandosi di metodi iterativi, le stime ottenute sono solo un'approssimazione (accettabile!) dei valori reali.\n\n##La regressione non-lineare con R\n\nLa funzione più comune in R per la parametrizzazione di funzioni non-lineari è nls(). Nella chiamata alla funzione dobbiamo anche fornire stime iniziali per i valori dei parametri. Ottenere queste stime è facile pensando al significato biologico dei parametri: $A$ è la concentrazione iniziale e quindi una stima ragionevole è data dal valor medio osservato al tempo 0 (100). Il parametro $k$ è invece il tasso di degradazione relativo; possiamo notare che nei primi 10 giorni la concentrazione si riduce della metà circa, cioè si abbassa mediamente un po' più del 5% al giorno (considerando che inizialmente il calo è più rapido). Possiamo quindi assegnare a $k$ un valore iniziale pari a 0.06.\n\n\n\n```{r}\nmodNlin <- nls(Conc ~ A*exp(-k*Time), start=list(A=100, k=0.06), data=degradation)\nsummary(modNlin)\n```\n\nIn alternativa, preferiamo utilizzare il package drc, con la funzione drm(), che ha un'infrastruttura molto comoda per le regressioni non-lineari in genere, compresa la definizione di funzioni di self-starting, che ci liberano dal problema di dover reperire le stime iniziali dei parametri. La chiamata è simile a quella di nls(), anche se vengono indicate separatamente le due variabili (Y ~ X) e la funzione (in questo caso il nome è EXD.2()).\n\n```{r}\nlibrary(drc)\nmodNlin2 <- drm(Conc ~ Time, fct=firstOrder(), data=degradation)\nsummary(modNlin2)\n```\n\n\n \n\n## Inferenze statistiche e verifiche delle assunzioni di base\n\nLe assunzioni parametriche di base relative ai modelli non-lineari sono le stesse dei modelli lineari e, di conseguenza, gli strumenti diagnostici sono analoghi. Bisogna tuttavia menzionare il fatto che, dato l'impiego di metodi iterativi per la ricerca dei valori dei parametri, tutti i risultati a cui si perviene (stima dei parametri, della varianza residua e numero dei gradi di libert? relativi) sono solo una approssimazione di quelli reali. Per questo motivo, nel caso non-lineare i metodi grafici (analisi dei residui) sono largamente preferiti.\n\nNel caso della regressione non-lineare, ? necessario valutare molto attentamente la correlazione tra i parametri, che pu? essere il sintomo di (sovraparametrizzazione), cio? di aver incluso nell'equazione un numero di parametri non giustificato dai dati sperimentali.\n\nPer quanto riguarda le trasformazioni stabilizzanti, valgono le stesse considerazioni relative ai modelli lineari ed ? possibile ricorrere alla famiglia di trasformazioni descritta da Box e Cox (1964). L'unica differenza rispetto alle regressioni lineari ? nel fatto che operare la trasformazione della sola variabile dipendente comporta anche la modifica della scala sulla quale vengono stimati i parametri, che quindi non conservano il loro valore biologico. Dato che spesso le regressioni non-lineari vengono eseguite proprio perch? si ? interessati all'informazione contenuta nei parametri di un modello, si preferisce adottare la cosiddetta tecnica della \"trasformazione di entrambe le parti\", o metodo TBS (''Transform Both Sides'') e trasformare quindi sia i dati osservati per la variabile dipendente, sia il modello:\n\n\\[\nY^\\lambda  = f(X)^\\lambda\n\\]\n\nIn questo modo si ottengono i parametri della funzione sulla scala originale come se la trasformazione non fosse stata eseguita per niente.\n\n%%tth:\\begin{html} <div class=\"pedicetop\"><a href=\"#Top\">Top</a><hr /></div> \\end{html}\n\\section{La regressione non-lineare con R}\n\nImmaginiamo di voler determinare la funzione di crescita di una coltura. I dati osservati sono:\n\n\\vspace{12pt} \n\\begin{tabular}{c c}\n\\hline\nGiorni & Peso \\\\\ndalla semina &  \\\\\n\\hline\n35.00 & 420.50 \\\\\n39.00 & 1660.70 \\\\\n46.00 & 3195.00 \\\\\n53.00 & 5870.10 \\\\\n60.00 & 7591.30 \\\\\n67.00 & 8784.80 \\\\\n74.00 & 9422.20 \\\\\n81.00 & 10328.10 \\\\\n\\hline\n\\end{tabular}\n\\vspace{12pt}\n\nVogliamo adattare ai dati anzidetti una funzione di Gompertz, del tipo:\n\n%%tth: \\begin{html} <br /> <img alt=\"\" src=\"NonLineare/Gompertz.gif\" /> <br /> \\end{html}\n\\tthdump{\n\\[\ny = a \\cdot \\exp ( - b \\cdot \\exp ( - c \\cdot x))\n\\]\n}\n\nPer eseguire la regressione non lineare possiamo utilizzare la funzione \\verb+nls()+, che ? gi? implementata nel package di base di R. La sintassi ? abbastanza semplice:\n\n\\begin{verbatim}\nnls(formula, start, trace)\n\\end{verbatim}\n\ndove formula ? la funzione da adattare ai dati, start ? la lista dei valori iniziali, trace (FALSE o TRUE) permette di richiedere la stampa a video dei risultati delle iterazioni.\n\n\\begin{verbatim}\n> dati\n  DAS      DW\n1  35   420.5\n2  39  1660.7\n3  46  3195.0\n4  53  5870.1\n5  60  7591.3\n6  67  8784.8\n7  74  9422.2\n8  81 10328.1\n\n> model<-nls(DW~a*exp(-exp(b*(c-DAS))), \n             start=list(a=10000, b=0.08, c=47), trace=TRUE, data=dati)\n2287456 :  1.0e+04 8.0e-02 4.7e+01 \n296223.3 :  1.079510e+04 8.320439e-02 4.769160e+01 \n294817.9 :  1.078999e+04 8.314129e-02 4.761957e+01 \n294817.7 :  1.078956e+04 8.315383e-02 4.761927e+01 \n294817.7 :  1.078956e+04 8.315391e-02 4.761925e+01 \n> summary(model)\n\nFormula: DW ~ a * exp(-exp(b * (c - DAS)))\n\nParameters:\n   Estimate Std. Error t value Pr(>t|)    \na 1.079e+04  3.351e+02   32.20 5.43e-07 ***\nb 8.315e-02  6.610e-03   12.58 5.64e-05 ***\nc 4.762e+01  6.470e-01   73.60 8.77e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nResidual standard error: 242.8 on 5 degrees of freedom\n\nCorrelation of Parameter Estimates:\n        a       b\nb -0.8455        \nc  0.7618 -0.5558\n\n> \n\\end{verbatim}\n\nIl vantaggio di \\verb+nls()+ ? che ? molto facile immettere una qualunque funzione, anche se non ? sempre altrettanto facile reperire delle stime iniziali dei parametri accettabili. In questo senso possono tornare utili alcune funzioni di \\textit{self starting} gi? implementate in R, che si occupano da sole del reperimento delle stime iniziali dei parametri. Per esempio, la funzione di Gompertz anzidetta pu? essere richiamata utilizzando la funzione \\verb+SSgompertz(X, Asym, b2, b3)+:\n\n\\begin{verbatim}\n> model<-nls(DW ~ SSgompertz(DAS, Asym, b2, b3), data=dati, trace=T) \n294817.7 :  1.078955e+04 5.244305e+01 9.202095e-01 \n> summary(model)\n\nFormula: DW ~ SSgompertz(DAS, Asym, b2, b3)\n\nParameters:\n      Estimate Std. Error t value Pr(>t|)    \nAsym 1.079e+04  3.351e+02  32.201 5.43e-07 ***\nb2   5.244e+01  1.512e+01   3.468   0.0179 *  \nb3   9.202e-01  6.083e-03 151.280 2.39e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\nResidual standard error: 242.8 on 5 degrees of freedom\n\nNumber of iterations to convergence: 0 \nAchieved convergence tolerance: 1.567e-06 |\n\\end{verbatim}\n\nAd oggi, esistono funzioni di \\textit{SelfStarting} per \\verb+nls()+ relative alle seguenti funzioni: \\verb+SSminmen(), SSlogis(), SSweibull()+. Per queste e per altre funzioni pu? essere reperito l'help all'interno di R.\n\nAll'interno del package aomisc ? possibile reperire: decrescita esponenziale (\\verb+NLSexpoDecay()+), equazione di Freundlich (\\verb+NLSpowerCurve()+), regressione logaritmica (\\verb+NLSlogReg+), esponenziale negativa  (\\verb+NLSnegExp()+), crescita monomolecolare (\\verb+NLSmonoGrowth()+), regressione asintotica (\\verb+NLSasymReg()+), crescita logistica a tre parametri (\\verb+NLSlogiGrowth()+), funzione di Hill (\\verb+NLShillCurve()+), Weibull (\\verb+NLSweibull()+).\n\n%%tth:\\begin{html} <div class=\"pedicetop\"><a href=\"#Top\">Top</a><hr /></div> \\end{html}\n\\section{Il package drc }\n\nOltre alla funzione \\verb+nls()+ in R esiste un package molto comodo, che si chiama \\verb+drc()+, che implementa tutte le funzioni necessarie per l'analisi di regressione non-lineare.\n\nDopo aver caricato il package con il comando:\n\n\\begin{verbatim}\nlibrary(drc)\n\\end{verbatim}\n\npossiamo utilizzare il dataset (incluso nel package) \\verb+beetGrowth+:\n\n\\begin{verbatim}\n> beetGrowth\n   DAE weightInf weightFree\n1   21   0.06000  0.0715091\n2   21   0.06000  0.0662547\n3   21   0.11000  0.0747931\n4   27   0.20000  0.3368074\n5   27   0.20000  0.3952256\n6   27   0.21000  0.2520960\n7   38   2.13000  2.3225072\n8   38   3.03000  1.7163224\n9   38   1.27000  1.2189231\n10  49   6.13000 11.7761096\n11  49   5.76000 13.6191507\n12  49   7.78000 12.1462931\n13  65  17.05000 33.1067720\n14  65  22.48000 24.9648226\n15  65  12.66000 34.6577561\n16 186  21.51010 38.8329912\n17 186  26.25887 27.8375016\n18 186  27.67733 37.7165427\n>\n\\end{verbatim}\n\nSi tratta della crescita di una coltura di barbabietola da zucchero in presenza ed in assenza di piante infestanti. Ai dati ? possibile adattare una funzione di Gompertz, in modo molto semplice:\n\n\\begin{verbatim}\nmodel <- drm(weightFree ~ DAE, data=beetGrowth, \n          fct=gompGrowth.1(), adjust=\"bc1\")\n\\end{verbatim}\n\nnotare l'argomento \\verb+fct+ che permette di specificare una funzione (scelta tra quelle disponibili), mentre l'argomento \\verb+adjust+ imlementa la procedura di Box e Cox, che sceglie automaticamente il valore di lambda pi? opportuno per la trasformazione.\n\nLa funzione \\verb+summary()+ restituisce le stime, indicando il valore lambda utilizzato per la correzione:\n\n\\begin{verbatim}\n> summary(model)\n\nModel fitted: Gompertz Growth Model (3 parms)\n\nParameter estimates:\n\n                      Estimate Std. Error    t-value   p-value\nc:(Intercept)        0.0507220  0.0040974 12.3790341 2.823e-09\nm:(Intercept)        0.9681277  0.1598079  6.0580709 2.191e-05\nplateau:(Intercept) 44.2395691  8.0757317  5.4780880     1e-04\n\nResidual standard error: 0.3730283 (15 degrees of freedom)\n\nNon-normality/heterogeneity adjustment through optimal Box-Cox\n transformation\n\nEstimated lambda: 0 \nConfidence interval for lambda: [-0.176,0.195]  \n\\end{verbatim}\n\nLa funzione \\verb+anova()+ esegue un test di lack of fit:\n\n\\begin{verbatim}\n> anova(model)\nLack-of-fit test\n\n              ModelDf     RSS Df F value p value\nOne-way ANOVA      12 0.46231                   \nDRC model          15 2.08725  3 14.0593  0.0003\n>\n\\end{verbatim}\n\nVediamo che, in questo caso il test ? significativo. La funzione \\verb+plot()+ permette di ottenere un grafico dei dati e della funzione. Per default, viene plottato il logaritmo della x, se ci? non corrisponde alla propria volont? ? necessario indicarlo, utilizzando l'argomento \\verb+log+:\n\n\\begin{verbatim}\n> plot(model)\n\\end{verbatim}\n\\includegraphics[width=10cm]{NonLineare/gompGrowth.jpg}\n\nOsserviamo che la funzione di Gompertz ? poco adatta, in quanto non permette una buona stima dell'asintoto superiore. Si pu? quindi provare ad utilizzare una funzione logistica, caricando il package \\verb+aomisc+, che la contiene:\n\n\\begin{verbatim}\n> library(aomisc)\n> model <- drm(weightFree ~ DAE, data=beetGrowth, \n+           fct=logiGrowth.1(), adjust=\"bc1\")\n> summary(model)\n\nModel fitted: Logistic Growth Model (3 parms)\n\nParameter estimates:\n\n                      Estimate Std. Error    t-value   p-value\ninit:(Intercept)    1.7457e-03 1.0406e-04 1.6776e+01 3.963e-11\nm:(Intercept)       1.8568e-01 2.9883e-03 6.2138e+01 8.205e-20\nplateau:(Intercept) 3.5417e+01 3.5683e+00 9.9253e+00 5.515e-08\n\nResidual standard error: 0.234448 (15 degrees of freedom)\n\nNon-normality/heterogeneity adjustment through optimal Box-Cox\n transformation\n\nEstimated lambda: 0 \nConfidence interval for lambda: [-0.176,0.195] \n\n> anova(model)\nLack-of-fit test\n\n              ModelDf     RSS Df F value p value\nOne-way ANOVA      12 0.46231                   \nDRC model          15 0.82449  3  3.1336  0.0656\n>\n\\end{verbatim}\n\nIn questo caso possiamo osservare che il fitting ? migliorato notevolmente.\nIl package \\verb+drc+ ? estremamente comodo, perch? contiene tutte le funzioni necessarie per eseguire analisi di regressione adeguate. Le funzioni disponibili (coni relativi \\textit{self-starter}) sono log-logistica a due tre e quattro parametri (\\verb+LL.2(), LL.3(), LL.4()+), weibull a due, tre, quattro parametri (\\verb+W1.2(), W1.3(), W1.4()+), sigmoidale con picco iniziale (\\verb+b3(), b4() e b5()+), Gompertz (tre parametrizzazioni alternative: \\verb+gompGrowth.1()+, \\verb+gompGrowth.2()+, \\verb+gompGrowth.3()+), decrescita esponenziale (\\verb+expDecay()+). Nella library aomisc sono contenute altre funzioni quali: allometrica (\\verb+allometric.1()+), crescita esponenziale (\\verb+expoGrowth()+), degradazione del primo ordine (\\verb+firstOrder()+), iperbole rettangolare (\\verb+hyperbolic.1()+), crescita logistica (tre parametrizzazioni alternative \\verb+logiGrowth.1(), logiGrowth.2(), logiGrowth.3()+), crescita monomolecolare (\\verb+monGrowth()+), equazione di Freundlich (\\verb+DRCpowerCurve()+), loglineare (\\verb+DRClogCurve()+), esponenziale negativa a due parametri (\\verb+DRCnegExp()+), regressione asintotica (\\verb+DRCasymReg()+), valori estremi (\\verb+DRCextremeValue()+), funzione di Hill (\\verb+DRChill()+), Chapman-Richard (\\verb+DRCchapman()+).\n\nE'possibile definire funzioni personalizzate, anche se non in modo semplice come con \\verb+nls()+.  \n\n%%tth:\\begin{html} <div class=\"pedicetop\"><a href=\"#Top\">Top</a><hr /></div> \\end{html}\n\\section{Ricerca dell'intervallo di confidenza per la X}\t\t \n\nIn taluni casi, abbastanza frequenti per la verit?, l' analisi di regressione viene eseguita per stimare o predire il valore della X corrispondente ad un dato $Y_{0}$. Per esempio, la concentrazione di un erbicida nel terreno pu? essere determinata misurando lo sviluppo di una pianta-test allevata su di esso. In questo caso ? necessario in primo luogo determinare la curva standard di risposta della pianta test allevata su terreno a concentrazione nota e successivamente utilizzare l' inversa della funzione di calibrazione per prevedere il valore di concentrazione di un terreno conoscendo lo sviluppo della pianta-test.\n\nMentre ? facile (con l'approssimazione lineare) stimare il limite di confidenza della Y per una data X, il problema contrario non ? di facile soluzione. Esistono due strade praticabili: la riparametrizzazione del modello e l'uso della banda d'inferenza per la risposta attesa.\n\nLa riparametrizzazione del modello ? una scelta utile; immaginiamo un modello di cinetica del primo ordine (esponenziale decrescente):\n\n\\[\nY = a \\cdot e^{- k \\cdot t}\n\\]\n\ndove \\textit{Y} ? la concentrazione di una sostanza, \\textit{t} ? il tempo, \\textit{a} ? la concentrazione iniziale mentre \\textit{k} ? il tasso di degradazione. Nella gran parte dei casi, questo modello viene utilizzato per prevedere la 'semivita', cio? il tempo richiesto per avere una concentrazione pari alla met? di quella iniziale (\\textit{a/2})\n\nSe $t_{1/2}$ ? la semivita, si pu? notare che:\n\n\n%%tth: \\begin{html} <br /> <img alt=\"\" src=\"NonLineare/semivita.gif\" /> <br /> \\end{html}\n\\tthdump{\n\\[\n\\begin{array}{l}\n a \\cdot \\exp ( - k \\cdot t_{1/2} ) = \\frac{a}{2} \\\\ \n \\exp ( - k \\cdot t_{1/2} ) = \\frac{1}{2} \\\\ \n ( - k \\cdot t_{1/2} ) = \\log \\left( {\\frac{1}{2}} \\right) \\\\ \n k \\cdot t_{1/2}  = \\log \\left( 2 \\right) \\\\ \n k = \\frac{{\\log \\left( 2 \\right)}}{{t_{1/2} }} \\\\ \n \\end{array}\n\\]\n}\n\nSi pu? quindi pensare di riparametrizzare il modello esponenziale in questo modo:\n\n%%tth: \\begin{html} <br /> <img alt=\"\" src=\"NonLineare/semivita2.gif\" /> <br /> \\end{html}\n\\tthdump{\n\\[\nY = a \\cdot \\exp ( - \\frac{{\\log \\left( 2 \\right)}}{{t_{1/2} }} \\cdot t )\n\\]\n}\n\nSi possono quindi ottenere i limiti di confidenza della semivita direttamente tramite l'analisi di regressione non-lineare.\n\nLa seconda strada percorribile ? quella di utilizzare la banda d'inferenza della risposta attesa per un dato X (Snedecor e Cochran, 1991). La procedura ? illustrata in figura e, dal punto di vista geometrico, il calcolo ? chiaro: data una curva e la banda di confidenza per la Y attesa (linee tratteggiate), i limiti di confidenza per la X corrispondente ad Y = 60 sono dati dai valori corrispondenti ai punti in cui la linea orizzontale passante per Y = 60 incontra le curve che delimitano la banda d' inferenza (0,17 e 0,21).\n\n%%tth:\\begin{html} <br /> \\end{html}\n%%tth:\\begin{html} <div class=\"figureNF\"> \\end{html}\n\\includegraphics[width=10cm]{NonLineare/confidenza.jpg}\n%%tth:\\begin{html} </div> \\end{html}\n%%tth:\\begin{html} <br /> \\end{html}\n\nLa soluzione numerica, immediata nel caso di regressioni lineari (vedi Bliss, 1967), non ? altrettanto semplice nel caso di regressioni non lineari; una soluzione esplicita non ? riportata in letteratura ed occorre quindi utilizzare metodi numerici di calcolo. Lo svantaggio di questa procedura ? che i limiti di confidenza cos? ottenuti non sono simmetrici.\n\n%%tth:\\begin{html} <div class=\"pedicetop\"><a href=\"#Top\">Top</a><hr /></div> \\end{html}\n\\section{Trasformazione del modello}\n\nLa trasformazione del modello dalla sua forma originaria in una forma alternativa pu? rendersi necessaria per diversi motivi:\n\n\\begin{enumerate}\n\\item il modello iniziale non presenta un buon adattamento ai dati sperimentali e l' analisi dei residui suggerisce deviazioni sistematiche che fanno pensare alla possibilit? di includere un ulteriore parametro. Per esempio nel caso in cui in una curva dose-risposta i residui sono prevalentemente positivi nella parte iniziale, facendo pensare all' esistenza di un effetto stimolante dell' erbicida a basse dosi.\n\n\\item Alcuni parametri non sono significativi. In questo caso ? bene eliminare i parametri dal modello. Talvolta l' eliminazione dei parametri non ? possibile e quindi pu? essere presa in considerazione la possibilit? di sostituire il parametro con un valore arbitrario determinato per esso sulla base dell' andamento dei dati sperimentali e di conoscenze pregresse di carattere biologico. Quest' ultima soluzione ? tuttavia da considerare con attenzione e da valutare con molto buon senso; l' inclusione di vincoli nel modello, in quanto operazione arbitraria, dovrebbe essere eseguita solo se non esistono ulteriori alternative (Streibig, 1980).\n\n\\item Alta correlazione tra i parametri. Anche in questo caso i parametri troppo correlati dovrebbero essere eliminati dal modello, considerando che ? sempre necessario utilizzare il modello pi? semplice tra quelli capaci di descrivere i dati in una certa situazione.\n\\end{enumerate}\n\nUna volta che il modello ? stato modificato, o in tutte le situazioni in cui pi? modelli possono essere impiegati per descrivere i dati sperimentali, pu? rendersi necessario un confronto, con il fine di valutare quale modello ? preferibile adottare.\n\nIn questo caso, ? necessario distinguere tra modelli annidati (\\textit{nested}) e non. I modelli annidati sono quelli in cui l' uno si riduce all' altro semplicemente uguagliando a zero uno o pi? parametri. In questo caso il confronto si esegue sulla base di un test di probabilit?, quale un test F.\nInfatti, l' esclusione di un parametro dal modello comporter? certamente un pi? o meno elevato incremento della devianza residua. Se $RSS_{c}$ ? la devianza residua del modello pi? complesso associata a $DF_{c}$ gradi di libert? e se $RSS_{i}$ ? il residuo del modello semplificato, associato a $DF_{i}$ gradi di libert?, l' incremento della devianza residua dovuto all' eliminazione dei parametri ? dato da $RSS_{i} - RSS_{c}$ con $DF_{i}-DF_{c}$ gradi di libert?. Il rapporto tra:\n\n%%tth: \\begin{html} <br /> <img alt=\"\" src=\"NonLineare\\Confronto.gif\" /> <br /> \\end{html}\n\n\\tthdump{\n\\[\nF_{(DF_i  - DF_c );\\alpha }  = \\frac{{\\frac{{(RSS_i  - RSS_c )}}{{(DF_i  - DF_c )}}}}{{\\frac{{RSS_c }}{{DF_c }}}}\n\\]\n}\n\nha una distribuzione F e pu? essere confrontato con i valori tabulati, per il prescelto livello di probabilit?. Se il test non risulta significativo il modello semplificato pu? essere ragionevolmente accettato.\n\nDa tener presente che anche in questo caso l' analisi risulta solamente approssimata, a causa della non-linearit? intrinseca dei parametri stimati.\n\nNel caso di modelli non nidificati, la scelta dovrebbe essere basata su considerazioni di natura biologica ed il modello pi? significativo in tal senso dovrebbe essere accettato. Se non esistono buone ragioni biologiche per preferire un modello all' altro ? bene scegliere il modello con la minore devianza residua e con la migliore distribuzione dei residui.\n\n\\begin{comment}\n%%tth:\\begin{html} <!-- \\end{html}\n\n\\section{Adattamento simultaneo di pi? curve}\n\nDato che con le regressioni non-lineari si tende a concentrare molta informazione biologica sui parametri stimati, si ? spesso interessati a verificare se esistono differenze significative tra diverse tesi sperimentali ed, in caso negativo, individuare un valore medio per i parametri stessi.\n\nIl problema viene risolto adattando simultaneamente la stessa curva alle diverse tesi sperimentali (adattamento simultaneo), analogamente a quanto si fa con le regressioni lineari (<a href=\"AdattamentoSimultaneo.htm\">si veda qui</a>).  L'unica differenza ? nel fatto che il modello deve essere codificato nella sua interezza, ricorrendo a variabili fittizie per la codifica delle tesi sperimentali.\n\nAd esempio, se abbiamo rilevato la cinetica di dissipazione di due erbicidi e vogliamo confrontarla tramite un modello del primo ordine, invece di eseguire due regressioni separate (una per ogni erbicida), possiamo creare due variabili fittizie (\\textit{dummy variables}) D1 e D2: \n\n<table class=\"BaseTab\">\n<tr><th>Erbicida</th><th>D1</th><th>D2</th><th>tempo</th><th>Conc.</th></tr>\n<tr><td>1</td><td>1</td><td>0</td><td>1</td><td>3</td></tr>\n<tr><td>1</td><td>1</td><td>0</td><td>5</td><td>2</td></tr>\n<tr><td>1</td><td>1</td><td>0</td><td>10</td><td>1</td></tr>\n<tr><td>1</td><td>1</td><td>0</td><td>20</td><td>0,5</td></tr>\n<tr><td>2</td><td>0</td><td>1</td><td>...</td><td>...</td></tr>\n<tr><td>2</td><td>0</td><td>1</td><td>...</td><td>...</td></tr>\n<tr><td>2</td><td>0</td><td>1</td><td>...</td><td>...</td></tr>\n<tr><td>2</td><td>0</td><td>1</td><td>...</td><td>...</td></tr>\n</table>\n\n\nIl modello pu? essere codificato in questo modo:\n\n<p class=\"Equation\">Y = (a1 &middot; D1 + a2 &middot; D1) &middot;  exp (-(k1 &middot; D1 + k2 &middot; D1) &middot; X)\n\nIl modello contiene inizialmente 4 parametri, cio? un valore a e un valore k per ognuna delle quattro tesi erbicide. Successivamente il modello pu? essere ridotto in questo modo:\n\n<p class=\"Equation\">Y = (a1 &middot; D1 + a2 &middot; D1) &middot;  exp (-k &middot; X)\n\nper avere un'unico valore di k (costante di dissipazione) per i due erbicidi. Il modello completo ed il modello ridotto, essendo naturalmente nidificati, possono essere confrontati con un test F.\n\n\nGli sviluppi di questa tecnica sono notevoli. Per esempio ? possibile includere l' effetto blocco nel modello (se l' esperimento ? stato organizzato a blocco randomizzato) e calcolare una curva diversa per ciascun blocco. Oppure ? possibile testare ipotesi di parallelismo tra curve e cos? via.\n\n\\section{Come ottenere le stime iniziali dei parametri}\n\nUno dei problemi pratici che ci si trova ad affrontare ? quello dell' ottenimento dei valori iniziali per i parametri. Infatti, soprattutto utilizzando metodi come il Gauss-Newton, basato sulla linearizzazione della funzione, le stime iniziali debbono essere piuttosto precise, altrimenti l' approssimazione che viene introdotta attraverso l' espansione delle serie di Taylor non ? pi? valida. In questo modo i valori dei parametri che si ottengono a ciascuna iterazione possono anche divergere da quelli reali.\n\nPer ottenere stime iniziali ci si basa sull' esperienza o sull' osservazione dei dati sperimentali. Verranno dati due esempi per due funzioni molto impiegate in biologia.\n\nDovendo adattare ai dati sperimentali una funzione sigmoidale decrescente con quattro parametri del tipo (curva dose-risposta):\n\n<img src=\"NonLineare_file/sigmoide.gif\" alt=\"\"> \n\ndove \\textit{C} rappresenta l' asintoto inferiore, \\textit{D} quello superiore, \\textit{a} il valore di ln(x) corrispondente al punto di flesso e \\textit{b} la pendenza nel punto di flesso, le stime iniziale possono essere ottenute prendendo per \\textit{C} il valore pi? basso tra quelli osservati e per \\textit{D} il valore pi? alto. Inoltre si pu? osservare che:\n \n<img src=\"NonLineare_file/logit.gif\" alt=\"\">\n\nQuindi trasformando i valori di \\textit{Y} come sopra indicato ed eseguendo un analisi di regressione sul logaritmo naturale di \\textit{x} ? possibile ottenere stime iniziali per \\textit{a} e \\textit{b}.\nNel caso di un funzione iperbolica:\n\n<img src=\"NonLineare_file/iperbole.gif\" alt=\"\"> \n\nil valore iniziale di \\textit{b} (asintoto dell' iperbole) pu? essere ottenuto prendendo il valore pi? alto tra quelli osservati, mentre il valore iniziale di \\textit{a} (pendenza della tangente all' iperbole nel punto X=0) si pu? ottenere prendendo la pendenza della retta di regressione della \\textit{Y} sulla \\textit{X}.\n%%tth:\\begin{html} --> \\end{html}\n\n\\end{comment}\n\n%%tth:\\begin{html} <div class=\"pedicetop\"><a href=\"#Top\">Top</a><hr /></div> \\end{html}\n\\section{Per approfondire}\n\nBates D. M. e Watts D. G., 1988. Nonlinear regression analysis and its applications. John Wiley and Sons, Inc., New York, pp.365\n\nBliss C. I., 1967. Statistics in biology. McGraw-Hill Inc., \nCarrol R. J. e Ruppert D., 1988. Transformation and weighting in regression. Chapman and Hall, London\n\nDraper N. R. e Smith H., 1981. Applied regression. John Wiley and Sons, Inc., New York, 2nd ed.\n \nGunther  P., 1991. Biotests mit hoheren Pflanzen zur Untersuchung und Bewertung des Verhaltens von Sulfonylharnstoff-Herbiziden un anderen Xenobiotika im Boden. Dissertation fur des akademischen Grades eines Doktors der Gartenbauwissenschaften, University of Hannover, Hannover\n\nMead R. e Pike D. J., 1975. A review of response surface methodology from a biometric viewpoint. Biometrics 31, 803-851.\n\nRatkowsky D.A., 1990. Handobook of nonlinear regression models. Marcell Dekker Inc., New York, 241 pp.\n\nRuppert D., Cressie N. e Carrol R. J., 1989. A trasformation/weighting model for estimating Michaelis-Menten parameters. Biometrics 45, 637.\n\nSnedecor G. W. e Cochran W. G., 1991. Statistical methods. IOWA State University Press, AMES (Iowa), pp.503\n\nStreibig J. C., 1980. Models for curve-fitting herbicide dose response data. Acta Agricolturae Scandinavica 30, 59-64.\n\n\n\n\\end{document}\n",
    "created" : 1519289649445.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2722815136",
    "id" : "FB633F06",
    "lastKnownWriteTime" : 1519307306,
    "last_content_update" : 1519310351142,
    "path" : "~/Documents/_DBXAndrea/Dropbox/_Lavoro/__Notes/__Stats/90 - NonLinearRegression/_dsp_NonLineare_conR/NonLineare.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}